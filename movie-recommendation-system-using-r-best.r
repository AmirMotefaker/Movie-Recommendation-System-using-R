{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amirmotefaker/movie-recommendation-system-using-r-best?scriptVersionId=124822059\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# What is Movie Recommendation?\n- A movie recommendation system, or a movie recommender system, is an ML-based approach to filtering or predicting the users’ film preferences based on their past choices and behavior. It’s an advanced filtration mechanism that predicts the possible movie choices of the concerned user and their preferences towards a domain-specific item, aka movie.\n\n# Filtration Strategies for Movie Recommendation Systems\n- The most popular categories of the ML algorithms used for movie recommendations include content-based filtering and collaborative filtering systems.\n    - Content-Based Filtering\n    - Collaborative Filtering\n        - Collaborative filtering algorithms are divided into two categories:\n\n            - User-based collaborative filtering. The idea is to look for similar patterns in movie preferences in the target user and other users in the database.\n            - Item-based collaborative filtering. The basic concept here is to look for similar items (movies) that target users rate or interact with.\n\n\n# How to Build a Movie Recommendation System?\n- The basics of film recommendation engines are in machine learning, we could on to building an actual movie recommendation system.\n    1. Data\n        - ML systems need data, so find and import the essential libraries with movie datasets that already have global ratings.\n    2. Analysis \n        - Create generic recommendations of top-rated movies from the existing dataset.\n    3. Personalization \n        - Get personalized ratings by providing your own movie scores.\n    4. Strategy \n        - Implement a content-based or collaborative filtering strategy.\n    5. Combination \n        - Combine recommendation lists to get a reasonable estimate across the ratings. The combined dataset of movie ratings can now be used for either filtering model.\n        \n# Best Movie Datasets for Recommendation Systems in ML\n- [MovieLens 25M data set](https://grouplens.org/datasets/movielens/)\n- [IMDB Datasets](https://www.imdb.com/interfaces/)\n- [Linguistic Data of 32k Film Subtitles with IMBDb Meta-Data](https://data.world/robertjoellewis/film-subtitles)\n- [Film data set from UCI](https://archive.ics.uci.edu/ml/datasets/Movie)\n- [Full MovieLens dataset on Kaggle](https://www.kaggle.com/rounakbanik/the-movies-dataset)\n- [Cornell Film Review Data](http://www.cs.cornell.edu/people/pabo/movie-review-data/)\n- [French National Cinema Center datasets](https://www.data.gouv.fr/fr/organizations/centre-national-du-cinema-et-de-l-image-animee/)\n- [Movie Industry on Kaggle](https://www.kaggle.com/danielgrijalvas/movies)\n- [Movie Body Counts](http://moviebodycounts.com/)\n- [Movie datasets on data.world](https://data.world/datasets/movies)\n\n# Top Movie Recommendation System Use Cases\n- [Netflix](https://www.netflix.com/)\n- [Amazon](https://www.primevideo.com/)\n- [YouTube](https://www.youtube.com/)\n\n##### Reference: [LabelYourData](https://labelyourdata.com/articles/movie-recommendation-with-machine-learning#introduction_to_the_movie_recommendation_system_architecture)\n\n# Important points of Movie Recommendation\n\n- Recommendation systems play an important role in e-commerce and online streaming services, such as Netflix, YouTube, and Amazon. Making the right recommendation for the next product, music or movie increases user retention and satisfaction, leading to sales and profit growth. Companies competing for customer loyalty invest in systems that capture and analyze the user’s preferences and offer products or services with a higher likelihood of purchase.\n\n- The economic impact of such a company-customer relationship is clear: Amazon is the largest online retail company by sales and part of its success comes from the recommendation system and marketing based on user preferences. In 2006 Netflix offered a one million dollar prize2 for the person or group that could improve their recommendation system by at least 10%.\n\n- Usually, recommendation systems are based on a rating scale from 1 to 5 grades or stars, with 1 indicating the lowest satisfaction and 5 being the highest satisfaction. Other indicators can also be used, such as comments posted on previously used items; video, music, or link shared with friends; percentage of movies watched or music listened; web pages visited and time spent on each page; product category; and any other interaction with the company’s web site or application can be used as a predictor.\n\n- The primary goal of recommendation systems is to help users find what they want based on their preferences and previous interactions and predict the rating for a new item. In this document, we create a movie recommendation system using the MovieLens dataset and apply the lessons learned during Harvard’s Data Science Professional Certificate3 program.\n\n- This document is structured as follows. Chapter 1 describes the dataset and summarizes the goal of the project and the key steps that were performed. In chapter 2 we explain the process and techniques used, such as data cleaning, data exploration, and visualization, any insights gained, and the modeling approach. In chapter 3 we present the modeling results and discuss the model performance. We conclude in chapter 4 with a brief summary of the report, its limitations, and future work.\n\n# MovieLens Dataset\n- GroupLens is a research lab at the [University of Minnesota](https://twin-cities.umn.edu/) that has collected and made available rating data for movies on the [MovieLens website](https://grouplens.org/datasets/movielens/).\n\n- The complete MovieLens dataset consists of 27 million ratings of 58,000 movies by 280,000 users. The research presented in this paper is based on a subset of this dataset with 10 million ratings on 10,000 movies by 72,000 users.\n\n# Most common loss functions in ML\n\n- Mean Absolute Error/L1 Loss (MAE)\n    - Mean absolute error, is measured as the average of the sum of absolute differences between predictions and actual observations. Like MSE, this as well measures the magnitude of error without considering their direction. Unlike MSE, MAE needs more complicated tools such as linear programming to compute the gradients. Plus MAE is more robust to outliers since it does not make use of squares.\n    \n    \n- Mean Square Error/Quadratic Loss/L2 Loss (MSE)\n    - Mean square error is measured as the average squared difference between predictions and actual observations. It’s only concerned with the average magnitude of error irrespective of their direction. However, due to squaring, predictions that are far away from actual values are penalized heavily in comparison to less deviated predictions. Plus MSE has nice mathematical properties which make it easier to calculate gradients.\n    \n    \n- Root Mean Square Error (RMSE)\n    - Root mean square error or root mean square deviation is one of the most commonly used measures for evaluating the quality of predictions. It shows how far predictions fall from measured true values using Euclidean distance.\n    - To compute RMSE, calculate the residual (difference between prediction and truth) for each data point, compute the norm of residual for each data point, compute the mean of residuals, and take the square root of that mean. RMSE is commonly used in supervised learning applications, as RMSE uses and needs true measurements at each predicted data point.","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle"}},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"markdown","source":"## Install Libraries","metadata":{}},{"cell_type":"code","source":"# if(!require(tidyverse)) \n#   install.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\n# if(!require(caret)) \n#   install.packages(\"caret\", repos = \"http://cran.us.r-project.org\")\n# if(!require(data.table)) \n#   install.packages(\"data.table\", repos = \"http://cran.us.r-project.org\")\n\n# Loading the required libraries\nlibrary(caret)\nlibrary(cowplot)\nlibrary(data.table)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(lubridate)\nlibrary(Metrics)\nlibrary(recosystem)\nlibrary(scales)\nlibrary(stringr)\nlibrary(tibble)\nlibrary(tidyr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Brief description about these libraries:\n    - [caret](https://www.rdocumentation.org/packages/caret/): this library’s name is short for “Classification And Regression Training”, being arguably the most popular R package for the matter. It contains a variety of tools to streamline machine learning tasks, and as such many of the functions used throughout this document are from within this package. \n    \n    - [cowplot](https://www.rdocumentation.org/packages/cowplot/): this library eases the construction of publication-quality figures.\n    \n    - [data.table](https://www.rdocumentation.org/packages/data.table/): a high-performance library to work, manipulate and operate with dataframes.\n    \n    - [dplyr](https://www.rdocumentation.org/packages/dplyr/): arguably the most popular R package for data manipulation. It provides a consistent set of tools for the matter, enabling data manipulation in an intuitive, user-friendly way. Data analysts typically use dplyr to transform existing datasets into a fitting format (dataframes are usually preferred) for data analysis, data exploration and data visualization tasks.\n    \n    - [ggplot2](https://www.rdocumentation.org/packages/ggplot2/): the most popular library for data visualization. It can greatly improve the quality and aesthetics of one’s graphics, being not only highly customizable but also remarkably efficient.\n\n    - [ggthemes](https://www.rdocumentation.org/packages/ggthemes/): ggplot2 and its official extension support allows developers to easily create their own tools and presets. ggthemes is built upon that support to provide additional themes for ggplot2’s graphics.\n    \n    - [lubridate](https://www.rdocumentation.org/packages/lubridate/): a library designed to simplify (and speed-up) time-related tasks and calculations.\n\n    - [Metrics](https://www.rdocumentation.org/packages/Metrics/): this library is built around evaluation metrics, providing functions to simplify their calculation. \n    \n    - [recosystem](https://www.rdocumentation.org/packages/recosystem/): this library is built around matrix factorization, bundling a collection of functions to simplify the process at hand.\n    \n    - [scales](https://www.rdocumentation.org/packages/scales/): this library was included to properly scale some plot’s axis to better visualize and understand the data being plotted.\n    \n    - [stringr](https://www.rdocumentation.org/packages/stringr/): this library a set of functions designed to make working with strings as easy as possible.\n    \n    - [tibble](https://www.rdocumentation.org/packages/tibble/): this library re-imagines the dataframe format, tidying it up leading to a cleaner solution.\n     \n    - [tidyr](https://www.rdocumentation.org/packages/tidyr/): this library simplifies the process of tidying data so that it can be easily evaluated/studied and standardizing it in format that most functions accept. ","metadata":{}},{"cell_type":"markdown","source":"## Read Dataset","metadata":{}},{"cell_type":"markdown","source":"## The MovieLens dataset\n- GroupLens Research has collected and made available rating data sets from the MovieLens web site (https://movielens.org). The data sets were collected over various periods of time, depending on the size of the set. Before using these data sets, please review their README files for the usage licenses and other details.\n\n- Dataset is provided by GroupLens (a research lab within the Univeristy of Minnesota) and holds 27 million ratings applied to 58,000 movies by 280,000 users. Once again, that might be too much to ask of most basic personal computers and would imply seriously long training times, so only a small subset of the whole dataset will be used given the sheer size of the latter (particularly, the exercise makes use of the [10M MovieLens subset](https://files.grouplens.org/datasets/movielens/ml-10m.zip)).\n\n## MovieLens 10M Dataset\n- MovieLens 10M movie ratings. Stable benchmark dataset. 10 million ratings and 100,000 tag applications applied to 10,000 movies by 72,000 users. Released 1/2009.\n\n    - [README.txt](https://files.grouplens.org/datasets/movielens/ml-10m-README.html)\n    - [ml-10m.zip](https://files.grouplens.org/datasets/movielens/ml-10m.zip) (size: 63 MB, [checksum](https://files.grouplens.org/datasets/movielens/ml-10m.zip.md5))\nPermalink: https://grouplens.org/datasets/movielens/10m/\n\n\n\n- ratings.dat: a four column dataset containing:\n\n    - A user ID\n    - A movie ID\n    - The score with which said user rated the movie\n    - A timestamp\n    \n    \n- movies.dat: a three column dataset containing:\n\n    - A movie ID\n    - The movie title\n    - The movie genres\n    \n    \n- tags.dat: a tag-related dataset that will not be used for this exercise.","metadata":{}},{"cell_type":"markdown","source":"## The ratings.dat is imported into the workspace\n- These files are to be worked with individually, just as is showcased in the next code snippet. The data has to be read properly, and there are various functions to perform this loading process like fread(), from the data.table library, and str_split_fixed(), from the stringr library. Each function has its own particular syntax, so informing oneself regarding their behavior, arguments, and intricacies is recommended.\n\n- Both ratings.dat and movies.dat have their column data separated with a “::” string, which needs to be properly specified in each of these functions. The column names should also be defined to facilitate indexing-related functions.\n\n- Both fread() and str_split_fixed() are showcased in the following code snippet, the former with the ratings.dat dataset and the latter with movies.dat (beware the computing time).","metadata":{}},{"cell_type":"code","source":"# MovieLens 10M dataset:\n# https://grouplens.org/datasets/movielens/10m/\n# http://files.grouplens.org/datasets/movielens/ml-10m.zip\n\nratings <- fread(text = gsub(\"::\", \"\\t\", \n                 readLines(\"/kaggle/input/movielens-10m-dataset-latest-version/ml-10M100K/ratings.dat\")),\n                 col.names = c(\"userId\", \"movieId\", \"rating\", \"timestamp\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class(ratings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(ratings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The movies.dat is imported into the workspace\n- The head() function outputs the structure of each set and its very first rows, whereas class() returns its class. Note that the fread() function outputs a data frame whereas str_split_fixed() outputs a matrix. Joining them together requires them both to be of equivalent format and, since most of the relevant functions work best (or at all) with data frames, the movies matrix will be converted to a data frame using the as.data.frame() function.\n\n- Note that the %>% operator corresponds to the pipe expression from the dplyr package, which allows functions to be easily chained. In the following code snippet, the pipe operator is used to easily apply the mutate() function (from that same dplyr package) upon the movie dataframe to properly “label” the columns’ content, changing their classes accordingly through the as.numeric() and as.character() functions. Beware that the mutate() function is usually used to create new columns for a data frame although, in this case, it is used to overwrite existing columns (using existing columns’ names).","metadata":{}},{"cell_type":"code","source":"movies <- str_split_fixed(readLines(\"/kaggle/input/movielens-10m-dataset-latest-version/ml-10M100K/movies.dat\"), \"\\\\::\", 3)\ncolnames(movies) <- c(\"movieId\", \"title\", \"genres\")\nclass(movies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(movies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The movies object is converted into a dataframe","metadata":{}},{"cell_type":"code","source":"movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),\n                                            title = as.character(title),\n                                            genres = as.character(genres))\nclass(movies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(movies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ratings and movies dataframes are joined by \"movieId\"\n\n- The head() output content is unchanged, but now class() showcases that movies have been properly converted into a data frame. Since both movies and ratings are now equal in format, they can be fused together with the left_join() function from the dplyr package, just as is illustrated in the following code snippet. Note that an array needs to be specified so that the two data frames can be joined (in this case, they are joined by the “movieId” column array).","metadata":{}},{"cell_type":"code","source":"movielens <- left_join(ratings, movies, by = \"movieId\")\nclass(movielens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(movielens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model evaluation","metadata":{}},{"cell_type":"markdown","source":"## The validation set\n- To evaluate the system’s effectiveness, a validation set is to be built using a small subset of the dataset at hand; it is upon this validation set that the RMSE will be computed. To split the movielens in a working set and the validation one the R built-in functions nrow() and sample() could be used to randomly select row indexes, dividing the dataset based on said indexes. This split is showcased in the following code snippet, where the validation set is built using 10% of the dataset’s indexes; the missing 90% is used to create the working_set object, which is the set to work upon and develop the model with.\nNote that the validation set is referred to as temp at this point since it is missing key steps without which it can be hardly considered a valid validation set. Finally, the tibble() function (from the tibble package) is used to create a table-like structure to showcase the different sets’ length.\n","metadata":{}},{"cell_type":"markdown","source":"## Using built-in R functions to create the working and validation sets","metadata":{}},{"cell_type":"code","source":"# set.seed(1, sample.kind=\"Rounding\") # if using R 3.5 or earlier, use `set.seed(1)`\nset.seed(1)\nvalidation_index <- sample(1:nrow(movielens), 0.1*nrow(movielens))\nworking_set <- movielens[-validation_index,]\ntemp <- movielens[validation_index,]\n\ntibble(Dataset = c(\"movielens\", \"working_set\", \"temp\"),\n       \"Number of ratings\" = c(nrow(movielens), nrow(working_set), nrow(temp)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Despite being perfectly valid, built-in R functions are not the usual/preferred approach for this sort of split. The caret package (short for Classification And Regression Training) contains a variety of tools to streamline many machine learning tasks (it is undoubtedly one of the most popular libraries for the matter) and among its many functions lies createDataPartition(), often used for the train-test split (which will be showcased later on) but equally ideal for the construction of the validation set. This function not only divides a given dataset based on a specified proportion but it does so while keeping the classification ratio constant within each set so that both have the same factor/cluster distribution as the original dataset, avoiding certain unfavorable scenarios where there might not be a sufficient amount of a given factor within the working set to allow the algorithm to develop a fitting model.","metadata":{}},{"cell_type":"code","source":"# # Do not run this code snippet, as it is only here for illustration purposes\n# library(caret)\n# createDataPartition(\n#   y,\n#   times = 1,\n#   p = 0.5,\n#   list = TRUE,\n#   groups = min(5, length(y))\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The arguments of the function are as follows:\n\n    - y: a vector of outcomes.\n    - times: the number of partitions to create.\n    - p: the percentage of data that goes to training.\n    - list: whether to hold the results within a list or within a matrix.\n    - groups: if y (the vector of outcomes) is numerical, then this argument defines the number of breaks in the quantiles.\n    \n- An important note is that, as opposed to the previous approach, the main argument of the function does not ask for the dataframe itself but uses its vector of outcomes instead (in the case of this exercise, said vector of outcomes is the ratings column/array). More information about the function, its behavior and its arguments can be found in its associated RDocumentation page.\n\n- The following code snippet showcases the subset construction using the createDataPartition() function. Note that, once again, the subsets’ balance is of 90% for the working set and 10% for the validation one.","metadata":{}},{"cell_type":"markdown","source":"## Using createDataPartition to create the working and validation sets","metadata":{}},{"cell_type":"code","source":"# set.seed(1, sample.kind=\"Rounding\") # if using R 3.5 or earlier, use `set.seed(1)`\nset.seed(1)\ntest_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)\nworking_set <- movielens[-test_index,]\ntemp <- movielens[test_index,]\n\ntibble(Dataset = c(\"movielens\", \"working_set\", \"temp\"),\n       \"Number of ratings\" = c(nrow(movielens), nrow(working_set), nrow(temp)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The tibble() function is used once again to observe the sets’ length. There might be minor differences with respect to the previous values (which used R built-in functions), but such differences are negligible.\n\n- Let’s now ensure the user IDs and movie IDs in the testing set are also present in the training set. To do so, different versions of the join() function (such as the previously used left_join()) are used (in this case, semi_join() and anti_join()). Any and all information regarding these functions can be found in their associated RDocumentation page.","metadata":{}},{"cell_type":"markdown","source":"## Make sure userId and movieId in validation set are also in working_set set","metadata":{}},{"cell_type":"code","source":"validation <- temp %>% \n      semi_join(working_set, by = \"movieId\") %>%\n      semi_join(working_set, by = \"userId\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add rows removed from validation set back into working_set set","metadata":{}},{"cell_type":"code","source":"removed <- anti_join(temp, validation)\nworking_set <- rbind(working_set, removed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data exploration","metadata":{}},{"cell_type":"code","source":"dim(working_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class(working_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"str(working_set, vec.len = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(working_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(working_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ratings","metadata":{}},{"cell_type":"code","source":"# Rating count\nworking_set %>%\n  group_by(rating) %>%\n  summarize(count = n())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Rating distribution plot","metadata":{}},{"cell_type":"code","source":"working_set %>%\n  group_by(rating) %>%\n  summarize(count = n()) %>%\n  ggplot(aes(x = rating, y = count)) +\n  geom_bar(stat = \"identity\", fill = \"#8888ff\") +\n  ggtitle(\"Rating Distribution\") +\n  xlab(\"Rating\") +\n  ylab(\"Occurrences Count\") +\n  scale_y_continuous(labels = comma) +\n  scale_x_continuous(n.breaks = 10) +\n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The graph confirms what was previously observed: rounded ratings occur more often than half-stared ones. The upwards trend previously discussed is now perfectly clear, although it seems to top right between the 3 and 4 star ratings lowering the occurrences count afterwards. That might be due to users being more hesitant to rate with the highest mark for whichever reasons they might hold.","metadata":{}},{"cell_type":"markdown","source":"# Timestamps","metadata":{}},{"cell_type":"code","source":"# as_datetime() showcase\nsample(as_datetime(working_set$timestamp, origin = \"1970-01-01\"), replace = TRUE, size = 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Yearly rating count","metadata":{}},{"cell_type":"code","source":"working_set %>% \n  mutate(year = year(as_datetime(timestamp, origin = \"1970-01-01\"))) %>%\n  group_by(year) %>%\n  summarize(count = n())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ratings per year plot","metadata":{}},{"cell_type":"code","source":"working_set %>% \n  mutate(year = year(as_datetime(timestamp, origin = \"1970-01-01\"))) %>%\n  ggplot(aes(x = year)) +\n  geom_bar(fill = \"#8888ff\") + \n  ggtitle(\"Ratings per year\") +\n  xlab(\"Year\") +\n  ylab(\"Number of ratings\") +\n  scale_y_continuous(labels = comma) + \n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Average rating per year plot","metadata":{}},{"cell_type":"code","source":"working_set %>% \n  mutate(year = year(as_datetime(timestamp, origin = \"1970-01-01\"))) %>%\n  group_by(year) %>%\n  summarize(avg = mean(rating)) %>%\n  ggplot(aes(x = year, y = avg)) +\n  geom_bar(stat = \"identity\", fill = \"#8888ff\") + \n  ggtitle(\"Average rating per year\") +\n  xlab(\"Year\") +\n  ylab(\"Average rating\") +\n  scale_y_continuous(labels = comma) + \n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ratings per movie","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:05:54.380746Z","iopub.execute_input":"2023-02-11T11:05:54.38241Z","iopub.status.idle":"2023-02-11T11:05:54.394505Z"}}},{"cell_type":"markdown","source":"## Movie popularity count","metadata":{}},{"cell_type":"code","source":"working_set %>% \n  group_by(movieId) %>% \n  summarize(count = n()) %>%\n  slice_head(n = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Movie popularity summary\nsummary(working_set %>% group_by(movieId) %>% summarize(count = n()) %>% select(count))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ratings per movie plot","metadata":{}},{"cell_type":"code","source":"working_set %>%\n  group_by(movieId) %>%\n  summarize(count = n()) %>%\n  ggplot(aes(x = movieId, y = count)) +\n  geom_point(alpha = 0.2, color = \"#4020dd\") +\n  geom_smooth(color = \"red\") +\n  ggtitle(\"Ratings per movie\") +\n  xlab(\"Movies\") +\n  ylab(\"Number of ratings\") +\n  scale_y_continuous(labels = comma) +\n  scale_x_continuous(n.breaks = 10) +\n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Movies' rating histogram","metadata":{}},{"cell_type":"code","source":"working_set %>%\n  group_by(movieId) %>%\n  summarize(count = n()) %>%\n  ggplot(aes(x = count)) +\n  geom_histogram(fill = \"#8888ff\", color = \"#4020dd\") +\n  ggtitle(\"Movies' rating histogram\") +\n  xlab(\"Rating count\") +\n  ylab(\"Number of movies\") +\n  scale_y_continuous(labels = comma) +\n  scale_x_log10(n.breaks = 10) +\n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- This histogram better conveys the information provided by the summary() function, where the quantiles’ values state that half the movies are rated between 30 and 565 times.","metadata":{}},{"cell_type":"markdown","source":"# Ratings per user","metadata":{}},{"cell_type":"markdown","source":"## User rating count (activity measure)","metadata":{}},{"cell_type":"code","source":"working_set %>% \n  group_by(userId) %>% \n  summarize(count = n()) %>%\n  slice_head(n = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# User rating summary","metadata":{}},{"cell_type":"code","source":"summary(working_set %>% group_by(userId) %>% summarize(count = n()) %>% select(count))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ratings per user plot","metadata":{}},{"cell_type":"code","source":"working_set %>%\n  group_by(userId) %>%\n  summarize(count = n()) %>%\n  ggplot(aes(x = userId, y = count)) +\n  geom_point(alpha = 0.2, color = \"#4020dd\") +\n  geom_smooth(color = \"red\") +\n  ggtitle(\"Ratings per user\") +\n  xlab(\"Users\") +\n  ylab(\"Number of ratings\") +\n  scale_y_continuous(labels = comma) +\n  scale_x_continuous(n.breaks = 10) +\n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Users' rating histogram\n","metadata":{}},{"cell_type":"code","source":"working_set %>%\n  group_by(userId) %>%\n  summarize(count = n()) %>%\n  ggplot(aes(x = count)) +\n  geom_histogram(fill = \"#8888ff\", color = \"#4020dd\") +\n  ggtitle(\"Users' rating histogram\") +\n  xlab(\"Rating count\") +\n  ylab(\"Number of users\") +\n  scale_y_continuous(labels = comma) +\n  scale_x_log10(n.breaks = 10) +\n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# User x Movie matrix construction","metadata":{}},{"cell_type":"code","source":"limit <- 60\nuser_movie_matrix <- working_set %>% \n  filter(userId %in% sample(unique(working_set$userId), limit)) %>%\n  select(userId, movieId, rating) %>%\n  mutate(rating = 1) %>%\n  spread(movieId, rating) %>% \n  select(sample(ncol(.), limit)) %>% \n  as.matrix() %>% \n  t(.) # This function transposes the matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Matrix plot\nuser_movie_matrix %>% \n  image(1:limit, 1:limit,., xlab = \"Movies\", ylab = \"Users\") +\n  abline(h = 0:limit + 0.5, v = 0:limit + 0.5, col = \"grey\") +\n  title(main = list(\"User x Movie matrix\", cex = 1, font = 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Genres","metadata":{}},{"cell_type":"markdown","source":"# Genres count","metadata":{}},{"cell_type":"code","source":"working_set %>% \n  group_by(genres) %>% \n  summarize(count = n()) %>%\n  slice_head(n = 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Individual genres count","metadata":{}},{"cell_type":"code","source":"genres <- c(\"Action\", \"Adventure\", \"Animation\", \n            \"Children\", \"Comedy\", \"Crime\", \n            \"Documentary\", \"Drama\", \"Fantasy\", \n            \"Film-Noir\", \"Horror\", \"Musical\", \n            \"Mystery\", \"Romance\", \"Sci-Fi\", \n            \"Thriller\", \"War\", \"Western\")\n\ngenres_df <- data.frame(\n  Genres = genres,\n  Count = sapply(genres, function(x) {\n    sum(str_detect(working_set$genres, x))\n  })\n)\n\nprint(genres_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Genre popularity plot","metadata":{}},{"cell_type":"code","source":"genres_df %>%\n  ggplot(aes(x = Count, y = Genres)) +\n  ggtitle(\"Genre Popularity\") +\n  geom_bar(stat = \"identity\", width = 0.6, fill = \"#8888ff\") +\n  xlab(\"Number of ratings\") +\n  ylab(\"Genres\") +\n  scale_x_continuous(labels = comma) +\n  theme_economist() +\n  theme(plot.title = element_text(vjust = 3.5),\n        axis.title.x = element_text(vjust = -5, face = \"bold\"),\n        axis.title.y = element_text(vjust = 10, face = \"bold\"),\n        axis.text.x = element_text(vjust = 1, hjust = 1, angle = 0),\n        axis.text.y = element_text(vjust = 0.25, hjust = 1, size = 12),\n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Average rating for each genre","metadata":{}},{"cell_type":"code","source":"genres_df_2 <- data.frame(\n  Genres = genres,\n  Rating = sapply(genres, function(x) {\n    mean(working_set[str_detect(working_set$genres, x)]$rating)\n  })\n)\nprint(genres_df_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Genre rating summary","metadata":{}},{"cell_type":"code","source":"summary(genres_df_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Genre rating plot","metadata":{}},{"cell_type":"code","source":"genres_df_2 %>%\n  ggplot(aes(x = Rating, y = Genres)) +\n  ggtitle(\"Genre Average Rating\") +\n  geom_bar(stat = \"identity\", width = 0.6, fill = \"#8888ff\") +\n  xlab(\"Average ratings\") +\n  ylab(\"Genres\") +\n  scale_x_continuous(labels = comma, limits = c(0.0, 5.0)) +\n  theme_economist() +\n  theme(plot.title = element_text(vjust = 3.5),\n        axis.title.x = element_text(vjust = -5, face = \"bold\"),\n        axis.title.y = element_text(vjust = 10, face = \"bold\"),\n        axis.text.x = element_text(vjust = 1, hjust = 1, angle = 0),\n        axis.text.y = element_text(vjust = 0.25, hjust = 1, size = 12),\n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How many rows and columns are there in the training dataset?\n","metadata":{}},{"cell_type":"code","source":"# Rows\ndim(working_set)[1] \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns\ndim(working_set)[2] \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How many zeros were given as ratings in the training dataset?","metadata":{}},{"cell_type":"code","source":"sum(working_set$rating == 0.0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How many threes were given as ratings in the training dataset?","metadata":{}},{"cell_type":"code","source":"sum(working_set$rating == 3.0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How many different movies are in the training dataset?","metadata":{}},{"cell_type":"code","source":"dim(as.data.frame(table(working_set$movieId)))[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How many different users are in the training dataset?","metadata":{}},{"cell_type":"code","source":"dim(as.data.frame(table(working_set$userId)))[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How many movie ratings belong to the drama, comedy, thriller and romance genres (respectively) in the working_set dataset?","metadata":{}},{"cell_type":"code","source":"genres_quiz <- c(\"Drama\", \"Comedy\", \"Thriller\", \"Romance\")\nsapply(genres_quiz, function(x) {\n  sum(str_detect(working_set$genres, x))\n})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Which of the following movies (“Forrest Gump”, “Jurassic Park”, “Pulp Fiction”, “Shawshank Redemption” and “Speed 2: Cruise Control”) has the greatest number of ratings?","metadata":{}},{"cell_type":"code","source":"ratings_quiz = c(\"Forrest Gump\", \n                 \"Jurassic Park \\\\(1993\", \n                 \"Pulp Fiction\", \n                 \"Shawshank Redemption\", \n                 \"Speed 2: Cruise Control\")\nsapply(ratings_quiz, function(x) {\n  sum(str_detect(working_set$title, x))\n})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What are the five most given ratings in order from most to least?","metadata":{}},{"cell_type":"code","source":"as.data.frame(table(working_set$rating)) %>% arrange(desc(Freq))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# System modelling","metadata":{}},{"cell_type":"markdown","source":"## Train-test split","metadata":{}},{"cell_type":"markdown","source":"### Train-test split using R built-in functions","metadata":{}},{"cell_type":"code","source":"# Approach 1: training index\n\n# set.seed(1, sample.kind=\"Rounding\") # if using R 3.5 or earlier, use `set.seed(1)`\nset.seed(1)\ntrain_index <- sample(1:nrow(movielens), 0.9*nrow(movielens))\ntrain_set <- movielens[train_index,]\ntemp_test_set <- movielens[-train_index,]\n\ntibble(Dataset = c(\"movielens\", \"train_set\", \"temp_test_set\"),\n       \"Number of ratings\" = c(nrow(movielens), nrow(train_set), nrow(temp_test_set)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Approach 2: testing index\n\n# set.seed(1, sample.kind=\"Rounding\") # if using R 3.5 or earlier, use `set.seed(1)`\nset.seed(1)\ntest_index <- sample(1:nrow(movielens), 0.1*nrow(movielens))\ntrain_set <- movielens[-test_index,]\ntemp_test_set <- movielens[test_index,]\n\ntibble(Dataset = c(\"movielens\", \"train_set\", \"temp_test_set\"),\n       \"Number of ratings\" = c(nrow(movielens), nrow(train_set), nrow(temp_test_set)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train-test split using createDataPartition\n","metadata":{}},{"cell_type":"code","source":"# Approach 1: training index\n\n# set.seed(1, sample.kind=\"Rounding\") # if using R 3.5 or earlier, use `set.seed(1)`\nset.seed(1)\ntrain_index <- createDataPartition(movielens$rating, times = 1, p = 0.9, list = FALSE)\ntrain_set <- movielens[train_index,]\ntemp_test_set <- movielens[-train_index,]\n\ntibble(Dataset = c(\"movielens\", \"train_set\", \"temp_test_set\"),\n       \"Number of ratings\" = c(nrow(movielens), nrow(train_set), nrow(temp_test_set)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Approach 2: testing index\n\n# set.seed(1, sample.kind=\"Rounding\") # if using R 3.5 or earlier, use `set.seed(1)`\nset.seed(1)\ntest_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)\ntrain_set <- movielens[-test_index,]\ntemp_test_set <- movielens[test_index,]\n\ntibble(Dataset = c(\"movielens\", \"train_set\", \"temp_test_set\"),\n       \"Number of ratings\" = c(nrow(movielens), nrow(train_set), nrow(temp_test_set)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make sure userId and movieId in the testing set are also in the training set set\ntest_set <- temp_test_set %>% \n      semi_join(train_set, by = \"movieId\") %>%\n      semi_join(train_set, by = \"userId\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add rows removed from the testing set back into the training set set\nremoved <- anti_join(temp_test_set, test_set)\ntrain_set <- rbind(train_set, removed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random guessing","metadata":{}},{"cell_type":"markdown","source":"### Random guessing model and predictions\n","metadata":{}},{"cell_type":"code","source":"rating_range <- seq(0.5, 5, 0.5)\nguess_right <- function(x, y) {\n  mean(y == x)\n}\n\n# set.seed(1, sample.kind=\"Rounding\") # if using R 3.5 or earlier, use `set.seed(1)`\nset.seed(1)\nsimulation <- replicate(10000, {\n  i <- sample(train_set$rating, 1000, replace = TRUE)\n  sapply(rating_range, guess_right, i)\n})\n\nguess_prob <- c()\nfor(i in 1:nrow(simulation)) {\n  guess_prob <- append(guess_prob, mean(simulation[i,]))\n}\n\ny_hat_random <- sample(rating_range, \n                       size = nrow(validation), \n                       replace = TRUE, \n                       prob = guess_prob)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation tibble construction\n","metadata":{}},{"cell_type":"code","source":"evaluation <- tibble(Model = c(\"Cinematch\", \"The Netflix Prize\", \"Random guessing\"),\n                     MAE = c(NA, NA, Metrics::mae(validation$rating, y_hat_random)),\n                     MSE = c(NA, NA, Metrics::mse(validation$rating, y_hat_random)),\n                     RMSE = c(0.9525, 0.85725, Metrics::rmse(validation$rating, y_hat_random)))\nprint(evaluation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linear Regression Model","metadata":{}},{"cell_type":"markdown","source":"## Mean Baseline","metadata":{}},{"cell_type":"markdown","source":"### Mean baseline model construction","metadata":{}},{"cell_type":"code","source":"mu <- mean(train_set$rating)\ny_hat_mean <- rep(mu, nrow(validation))\n\nevaluation <- bind_rows(evaluation, tibble(Model = \"Linear model (mean baseline)\",\n                                           MAE = Metrics::mae(validation$rating, y_hat_mean),\n                                           MSE = Metrics::mse(validation$rating, y_hat_mean),\n                                           RMSE = Metrics::rmse(validation$rating, y_hat_mean)))\nprint(evaluation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Movie bias","metadata":{}},{"cell_type":"markdown","source":"### Bias per movie table","metadata":{}},{"cell_type":"code","source":"b_i <- train_set %>%\n  group_by(movieId) %>% \n  summarize(b_i = mean(rating - mu),\n            b_i_isolated = mean(rating))\nb_i %>% slice_head(n = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Isolated movie bias plot","metadata":{}},{"cell_type":"code","source":"b_i_isolated_plot <- b_i %>%\n  ggplot(aes(x = b_i_isolated)) + \n  geom_histogram(bins = 20, fill = \"#8888ff\", color = \"#4020dd\") +\n  ggtitle(\"Movie Bias (isolated)\") +\n  xlab(\"Bias value\") +\n  ylab(\"Count\") +\n  scale_y_continuous(labels = comma) +\n  scale_x_continuous(n.breaks = 10) +\n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adjusted movie bias plot","metadata":{}},{"cell_type":"code","source":"b_i_plot <- b_i %>%\n  ggplot(aes(x = b_i)) + \n  geom_histogram(bins = 20, fill = \"#8888ff\", color = \"#4020dd\") +\n  ggtitle(\"Movie Bias (adjusted)\") +\n  xlab(\"Bias value\") +\n  ylab(\"Count\") +\n  scale_y_continuous(labels = comma) +\n  scale_x_continuous(n.breaks = 10) +\n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Both b_i plots are combined with plot_grid()","metadata":{}},{"cell_type":"code","source":"plot_grid(b_i_isolated_plot, b_i_plot, labels = \"AUTO\", nrow = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Linear Model construction (mean + movie bias)","metadata":{}},{"cell_type":"code","source":"y_hat_b_i <- mu + validation %>%\n  left_join(b_i, by = \"movieId\") %>%\n  .$b_i\n\nevaluation <- bind_rows(evaluation,\n                        tibble(Model = \"Linear model (mean + movie bias)\",\n                               MAE = Metrics::mae(validation$rating, y_hat_b_i),\n                               MSE = Metrics::mse(validation$rating, y_hat_b_i),\n                               RMSE = Metrics::rmse(validation$rating, y_hat_b_i)))\nprint(evaluation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## User bias","metadata":{}},{"cell_type":"markdown","source":"### Bias per user","metadata":{}},{"cell_type":"code","source":"b_u <- train_set %>%\n  left_join(b_i, by = 'movieId') %>%\n  group_by(userId) %>% \n  summarize(b_u = mean(rating - mu - b_i),\n            b_u_isolated = mean(rating))\nb_u %>% slice_head(n = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Isolated user bias plot","metadata":{}},{"cell_type":"code","source":"b_u_isolated_plot <- b_u %>%\n  ggplot(aes(x = b_u_isolated)) + \n  geom_histogram(bins = 20, fill = \"#8888ff\", color = \"#4020dd\") +\n  ggtitle(\"User Bias (isolated)\") +\n  xlab(\"Bias value\") +\n  ylab(\"Count\") +\n  scale_y_continuous(labels = comma) +\n  scale_x_continuous(n.breaks = 10) +\n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adjusted user bias plot","metadata":{}},{"cell_type":"code","source":"b_u_plot <- b_u %>%\n  ggplot(aes(x = b_u)) + \n  geom_histogram(bins = 20, fill = \"#8888ff\", color = \"#4020dd\") +\n  ggtitle(\"User Bias (adjusted)\") +\n  xlab(\"Bias value\") +\n  ylab(\"Count\") +\n  scale_y_continuous(labels = comma) +\n  scale_x_continuous(n.breaks = 10) +\n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Both b_u plots are combined with plot_grid()","metadata":{}},{"cell_type":"code","source":"plot_grid(b_u_isolated_plot, b_u_plot, labels = \"AUTO\", nrow = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Linear model construction (mean + movie bias + user bias)","metadata":{}},{"cell_type":"code","source":"y_hat_b_u <- validation %>%\n  left_join(b_i, by='movieId') %>%\n  left_join(b_u, by='userId') %>%\n  mutate(y_hat = mu + b_i + b_u) %>%\n  .$y_hat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"evaluation <- bind_rows(evaluation, \n                        tibble(Model = \"Linear model (mean + movie and user bias)\",\n                               MAE = Metrics::mae(validation$rating, y_hat_b_u),\n                               MSE = Metrics::mse(validation$rating, y_hat_b_u),\n                               RMSE = Metrics::rmse(validation$rating, y_hat_b_u)))\nprint(evaluation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Movie recommendations\n- To obtain recommendations for our users, we will predict their ratings for movies they haven't watched yet.","metadata":{}},{"cell_type":"markdown","source":"## Top 10 movie recommendation by the linear model","metadata":{}},{"cell_type":"code","source":"top10_prediction_linear <- test_set %>%\n  left_join(b_i, by = \"movieId\") %>%\n  left_join(b_u, by = \"userId\") %>%\n  mutate(y_hat = mu + b_i + b_u) %>%\n  arrange(desc(y_hat)) %>%\n  select(title) %>%\n  unique() %>%\n  slice_head(n = 10)\ntop10_prediction_linear_df <- data.frame(Title = top10_prediction_linear,\n                                         Rating = rep(NA, 10), \n                                         Count = rep(NA, 10))\n\nfor (i in 1:10) {\n  indexes <- which(test_set$title == as.character(top10_prediction_linear[i]))\n  top10_prediction_linear_df$Rating[i] <- mean(test_set$rating[indexes])\n  top10_prediction_linear_df$Count[i] <- sum(\n    test_set$title == as.character(top10_prediction_linear[i])\n  )\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top10 Prediction","metadata":{}},{"cell_type":"code","source":"print(top10_prediction_linear_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Worst 10 movie recommendation by the linear model","metadata":{}},{"cell_type":"code","source":"worst10_prediction_linear <- test_set %>%\n  left_join(b_i, by = \"movieId\") %>%\n  left_join(b_u, by = \"userId\") %>%\n  mutate(y_hat = mu + b_i + b_u) %>%\n  arrange(b_i) %>%\n  select(title) %>%\n  unique() %>%\n  slice_head(n = 10)\nworst10_prediction_linear_df <- data.frame(Title = worst10_prediction_linear,\n                                           Rating = rep(NA, 10),\n                                           Count = rep(NA, 10))\n\nfor (i in 1:10) {\n  indexes <- which(test_set$title == as.character(worst10_prediction_linear[i]))\n  worst10_prediction_linear_df$Rating[i] <- mean(test_set$rating[indexes])\n  worst10_prediction_linear_df$Count[i] <- sum(\n    test_set$title == as.character(worst10_prediction_linear[i])\n  )\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Worst10 Prediction","metadata":{}},{"cell_type":"code","source":"print(worst10_prediction_linear_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Regularization","metadata":{}},{"cell_type":"markdown","source":"## Regularization function\n- Using Regularization, we can fit our machine learning model appropriately on a given test set and hence reduce the errors in it.","metadata":{}},{"cell_type":"code","source":"regularization <- function(lambda, train_set, test_set){\n  mu <- mean(train_set$rating)\n\n  b_i <- train_set %>% \n    group_by(movieId) %>%\n    summarize(b_i = sum(rating - mu) / (n() + lambda))\n\n  b_u <- train_set %>% \n    left_join(b_i, by=\"movieId\") %>%\n    filter(!is.na(b_i)) %>%\n    group_by(userId) %>%\n    summarize(b_u = sum(rating - mu - b_i) / (n() + lambda))\n\n  predicted_ratings <- test_set %>% \n    left_join(b_i, by = \"movieId\") %>%\n    left_join(b_u, by = \"userId\") %>%\n    filter(!is.na(b_i), !is.na(b_u)) %>%\n    mutate(pred = mu + b_i + b_u) %>%\n    pull(pred)\n  \n  return(Metrics::rmse(predicted_ratings, test_set$rating))\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The regularization function at play\n- Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting. ","metadata":{}},{"cell_type":"code","source":"lambdas <- seq(0, 10, 0.25)\nlambdas_rmse <- sapply(lambdas,\n                       regularization, \n                       train_set = train_set, \n                       test_set = test_set)\nlambdas_tibble <- tibble(Lambda = lambdas, RMSE = lambdas_rmse)\nprint(lambdas_tibble)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lambda's effect on RMSE(root-mean-square error) plot\n- Root mean square error or root mean square deviation is one of the most commonly used measures for evaluating the quality of predictions.","metadata":{}},{"cell_type":"code","source":"lambdas_tibble %>%\n  ggplot(aes(x = Lambda, y = RMSE)) +\n  geom_point() +\n  ggtitle(\"Lambda's effect on RMSE\") +\n  xlab(\"Lambda\") +\n  ylab(\"RMSE\") +\n  scale_y_continuous(n.breaks = 6, labels = comma) +\n  scale_x_continuous(n.breaks = 10) +\n  theme_economist() +\n  theme(axis.title.x = element_text(vjust = -5, face = \"bold\"), \n        axis.title.y = element_text(vjust = 10, face = \"bold\"), \n        plot.margin = margin(0.7, 0.5, 1, 1.2, \"cm\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Regularized linear model construction\n- During the Machine Learning model building, the Regularization Techniques is an unavoidable and important step to improve the model prediction and reduce errors.","metadata":{}},{"cell_type":"code","source":"lambda <- lambdas[which.min(lambdas_rmse)]\n\nmu <- mean(train_set$rating)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"b_i_regularized <- train_set %>% \n  group_by(movieId) %>%\n  summarize(b_i = sum(rating - mu)/(n()+lambda))\n\nb_u_regularized <- train_set %>% \n  left_join(b_i, by=\"movieId\") %>%\n  group_by(userId) %>%\n  summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))\n\ny_hat_regularized <- validation %>% \n  left_join(b_i_regularized, by = \"movieId\") %>%\n  left_join(b_u_regularized, by = \"userId\") %>%\n  mutate(prediction = mu + b_i + b_u) %>%\n  pull(prediction)\n\nevaluation <- bind_rows(evaluation,\n                        tibble(Model = \"Linear model with regularized bias\",\n                               MAE  = Metrics::mae(validation$rating, y_hat_regularized),\n                               MSE  = Metrics::mse(validation$rating, y_hat_regularized),\n                               RMSE = Metrics::rmse(validation$rating, y_hat_regularized)))\nprint(evaluation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Movie recommendations","metadata":{}},{"cell_type":"markdown","source":"## Top 10 movie recommendation by the regularized linear model","metadata":{}},{"cell_type":"code","source":"top10_prediction_regularized <- test_set %>%\n  left_join(b_i_regularized, by = \"movieId\") %>%\n  left_join(b_u_regularized, by = \"userId\") %>%\n  mutate(y_hat = mu + b_i + b_u) %>%\n  arrange(desc(y_hat)) %>%\n  select(title) %>%\n  unique() %>%\n  slice_head(n = 10)\ntop10_prediction_regularized_df <- data.frame(Title = top10_prediction_regularized,\n                                              Rating = rep(NA, 10),\n                                              Count = rep(NA, 10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (i in 1:10) {\n  indexes <- which(test_set$title == as.character(top10_prediction_regularized[i]))\n  top10_prediction_regularized_df$Rating[i] <- mean(test_set$rating[indexes])\n  top10_prediction_regularized_df$Count[i] <- sum(\n    test_set$title == as.character(top10_prediction_regularized[i])\n  )\n}\nprint(top10_prediction_regularized_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Worst 10 movie recommendation by the regularized linear model","metadata":{}},{"cell_type":"code","source":"worst10_prediction_regularized <- test_set %>%\n  left_join(b_i_regularized, by = \"movieId\") %>%\n  left_join(b_u_regularized, by = \"userId\") %>%\n  mutate(y_hat = mu + b_i + b_u) %>%\n  arrange(y_hat) %>%\n  select(title) %>%\n  unique() %>%\n  slice_head(n = 10)\nworst10_prediction_regularized_df <- data.frame(Title = worst10_prediction_regularized,\n                                                Rating = rep(NA, 10),\n                                                Count = rep(NA, 10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (i in 1:10) {\n  indexes <- which(test_set$title == as.character(worst10_prediction_regularized[i]))\n  worst10_prediction_regularized_df$Rating[i] <- mean(test_set$rating[indexes])\n  worst10_prediction_regularized_df$Count[i] <- sum(\n    test_set$title == as.character(worst10_prediction_regularized[i])\n  )\n}\nprint(worst10_prediction_regularized_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Matrix factorization","metadata":{}},{"cell_type":"markdown","source":"## 1. The training and testing sets need to be converted into recosystem input format","metadata":{}},{"cell_type":"code","source":"# set.seed(1, sample.kind=\"Rounding\") # if using R 3.5 or earlier, use `set.seed(1)`\nset.seed(1)\ntrain_recosystem <- with(train_set, data_memory(user_index = userId, \n                                                item_index = movieId,\n                                                rating     = rating))\ntest_recosystem <- with(test_set, data_memory(user_index = userId, \n                                              item_index = movieId, \n                                              rating     = rating))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. The model object is created","metadata":{}},{"cell_type":"code","source":"recommendation_system <- Reco()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. The model is tuned","metadata":{}},{"cell_type":"code","source":"tuning <- recommendation_system$tune(train_recosystem, opts = list(dim = c(10, 20, 30),\n                                                                   lrate = c(0.1, 0.2),\n                                                                   nthread  = 4,\n                                                                   niter = 10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. The model is trained","metadata":{}},{"cell_type":"code","source":"recommendation_system$train(train_recosystem, opts = c(tuning$min,\n                                                       nthread = 4,\n                                                       niter = 20))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. A prediction is made","metadata":{}},{"cell_type":"code","source":"y_hat_MF <-  recommendation_system$predict(test_recosystem, out_memory())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The model's RMSE is computed and added to the evaluation table\n\n- Why is Root Mean Square Error (RMSE) Important? In machine learning, it is extremely helpful to have a single number to judge a model's performance, whether it be during training, cross-validation, or monitoring after deployment. Root mean square error is one of the most widely used measures for this.","metadata":{}},{"cell_type":"code","source":"evaluation <- bind_rows(evaluation,\n                        tibble(Model = \"Matrix factorization\",\n                               MAE  = Metrics::mae(validation$rating, y_hat_MF),\n                               MSE  = Metrics::mse(validation$rating, y_hat_MF),\n                               RMSE = Metrics::rmse(validation$rating, y_hat_MF)))\nprint(evaluation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Movie Recommendations","metadata":{}},{"cell_type":"markdown","source":"## Top 10 movie recommendation by the matrix factorization model","metadata":{}},{"cell_type":"code","source":"top10_prediction_MF <- tibble(title = test_set$title, y_hat = y_hat_MF) %>%\n  arrange(desc(y_hat)) %>%\n  select(title) %>%\n  unique() %>%\n  slice_head(n = 10)\ntop10_prediction_MF_df <- data.frame(Title = top10_prediction_MF,\n                                     Rating = rep(NA, 10),\n                                     Count = rep(NA, 10))\n\nfor (i in 1:10) {\n  indexes <- which(test_set$title == as.character(top10_prediction_MF[i,]))\n  top10_prediction_MF_df$Rating[i] <- mean(test_set$rating[indexes])\n  top10_prediction_MF_df$Count[i] <- sum(\n    test_set$title == as.character(top10_prediction_MF[i,])\n  )\n}\nprint(top10_prediction_MF_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Worst 10 movie recommendation by the matrix factorization model","metadata":{}},{"cell_type":"code","source":"worst10_prediction_MF <- tibble(title = test_set$title, y_hat = y_hat_MF) %>%\n  arrange(y_hat) %>%\n  select(title) %>%\n  unique() %>%\n  slice_head(n = 10)\nworst10_prediction_MF_df <- data.frame(Title = worst10_prediction_MF,\n                                       Rating = rep(NA, 10),\n                                       Count = rep(NA, 10))\n\nfor (i in 1:10) {\n  indexes <- which(test_set$title == as.character(worst10_prediction_MF[i,]))\n  worst10_prediction_MF_df$Rating[i] <- mean(test_set$rating[indexes])\n  worst10_prediction_MF_df$Count[i] <- sum(\n    test_set$title == as.character(worst10_prediction_MF[i,])\n  )\n}\nprint(worst10_prediction_MF_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n- This project details to a considerable length the process of building a recommender system. The MovieLens dataset has been loaded and manipulated to fit the workspace, and its content has been thoughtfully explored with many of its most relevant aspects being plotted for its proper visual examination. A baseline model was built through random guessing, after which both a linear model and a matrix factorization-based model were developed. Both of these models represent different approaches in the construction of a recommender system: the first one was the one upon which the Cinematch algorithm was built whereas the latter one was the approach to dethrone Cinematch in The Netflix Prize challenge.\n\n- All in all, both models provide reliable approaches as shown in the evaluation table/tibble and through the recommended movies. However, having used both, it is undeniable that matrix factorization yields better results (as was to be expected since the linear nature of linear models usually leads to underfitting issues in non-linear data). Increasing the model’s dimensionality allow the model to better represent more complex data distributions at the risk of overfitting (as is, overly adapted to the supplied data and not generalizable to new data), so a validation test was an utmost necessity.","metadata":{}}]}